{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOpBtAWIr42sIDUTk1yj9TN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eunicean/Proyecto-DeepLearning/blob/main/CNN/HIRAGANA_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "v-kLZQtSko7H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3fcf4047-782e-4309-b34f-58dce141dfdb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Colab cache for faster access to the 'handwritten-japanese-hiragana-characters' dataset.\n",
            "Path to dataset files: /root/.cache/kagglehub/datasets/farukece/handwritten-japanese-hiragana-characters/versions/1\n"
          ]
        }
      ],
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "dataset_path = kagglehub.dataset_download(\"farukece/handwritten-japanese-hiragana-characters\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "from collections import Counter\n"
      ],
      "metadata": {
        "id": "fPngC5ZvnnHL"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for root, dirs, files in os.walk(dataset_path):\n",
        "    level = root.replace(dataset_path, '').count(os.sep)\n",
        "    indent = ' ' * 2 * level\n",
        "    print(f'{indent}{os.path.basename(root)}/')\n",
        "\n",
        "    # Solo mostrar los primeros niveles para no saturar\n",
        "    if level < 2:\n",
        "        subindent = ' ' * 2 * (level + 1)\n",
        "        for file in files[:5]:  # Mostrar solo los primeros 5 archivos\n",
        "            print(f'{subindent}{file}')\n",
        "        if len(files) > 5:\n",
        "            print(f'{subindent}... y {len(files) - 5} archivos más')\n",
        "\n",
        "    if level >= 3:\n",
        "        break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YNv2lkwWnb8j",
        "outputId": "41351a26-e021-4af3-e438-45c67051828d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "handwritten-japanese-hiragana-characters/\n",
            "  hiragana/\n",
            "    nn/\n",
            "    he/\n",
            "    no/\n",
            "    mu/\n",
            "    na/\n",
            "    se/\n",
            "    so/\n",
            "    wa/\n",
            "    ko/\n",
            "    yo/\n",
            "    ra/\n",
            "    wo/\n",
            "    ta/\n",
            "    ro/\n",
            "    mo/\n",
            "    ne/\n",
            "    su/\n",
            "    ii/\n",
            "    nu/\n",
            "    to/\n",
            "    ri/\n",
            "    chi/\n",
            "    ke/\n",
            "    te/\n",
            "    ya/\n",
            "    me/\n",
            "    ma/\n",
            "    mi/\n",
            "    re/\n",
            "    uu/\n",
            "    fu/\n",
            "    ho/\n",
            "    tsu/\n",
            "    ru/\n",
            "    yu/\n",
            "    shi/\n",
            "    aa/\n",
            "    ku/\n",
            "    ni/\n",
            "    oo/\n",
            "    ki/\n",
            "    hi/\n",
            "    ee/\n",
            "    ka/\n",
            "    ha/\n",
            "    sa/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Analizar cada carpeta de hiragana\n",
        "hiragana_path = os.path.join(dataset_path, \"hiragana\")\n",
        "\n",
        "# Diccionario para almacenar la información\n",
        "hiragana_data = {}\n",
        "\n",
        "print(\"Conteo de imágenes por carácter Hiragana:\")\n",
        "\n",
        "for character_folder in sorted(os.listdir(hiragana_path)):\n",
        "    folder_path = os.path.join(hiragana_path, character_folder)\n",
        "\n",
        "    if os.path.isdir(folder_path):\n",
        "        # Contar archivos de imagen\n",
        "        image_files = [f for f in os.listdir(folder_path)\n",
        "                      if f.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif'))]\n",
        "\n",
        "        hiragana_data[character_folder] = {\n",
        "            'num_imagenes': len(image_files),\n",
        "            'ruta': folder_path,\n",
        "            'archivos': image_files\n",
        "        }\n",
        "\n",
        "        print(f\"{character_folder:8s} tiene {len(image_files):3d} imágenes\")\n",
        "\n",
        "# Crear DataFrame para análisis\n",
        "df_hiragana = pd.DataFrame.from_dict(hiragana_data, orient='index')\n",
        "df_hiragana = df_hiragana.reset_index().rename(columns={'index': 'caracter'})\n",
        "\n",
        "print(\"\\n\")\n",
        "print(f\"RESUMEN:\")\n",
        "print(f\"Total de caracteres: {len(df_hiragana)}\")\n",
        "print(f\"Total de imágenes: {df_hiragana['num_imagenes'].sum()}\")\n",
        "print(f\"\\nEstadísticas:\")\n",
        "print(f\"  - Mínimo: {df_hiragana['num_imagenes'].min()} imágenes\")\n",
        "print(f\"  - Máximo: {df_hiragana['num_imagenes'].max()} imágenes\")\n",
        "print(f\"  - Promedio: {df_hiragana['num_imagenes'].mean():.2f} imágenes\")\n",
        "print(f\"  - Mediana: {df_hiragana['num_imagenes'].median():.0f} imágenes\")\n",
        "\n",
        "# Verificar si todas las clases tienen 100 imágenes\n",
        "clases_con_100 = df_hiragana[df_hiragana['num_imagenes'] == 100]\n",
        "print(f\"\\nClases con exactamente 100 imágenes: {len(clases_con_100)}/{len(df_hiragana)}\")\n",
        "\n",
        "if len(df_hiragana) != len(clases_con_100):\n",
        "    print(\"\\nClases con cantidad diferente a 100:\")\n",
        "    clases_diferentes = df_hiragana[df_hiragana['num_imagenes'] != 100]\n",
        "    for _, row in clases_diferentes.iterrows():\n",
        "        print(f\"  - {row['caracter']}: {row['num_imagenes']} imágenes\")"
      ],
      "metadata": {
        "id": "VHWI_am-pqMC",
        "outputId": "d072dfc0-cc8e-4f10-d1c4-b42c667d5018",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Conteo de imágenes por carácter Hiragana:\n",
            "aa       tiene 100 imágenes\n",
            "chi      tiene 100 imágenes\n",
            "ee       tiene 100 imágenes\n",
            "fu       tiene 100 imágenes\n",
            "ha       tiene 100 imágenes\n",
            "he       tiene 100 imágenes\n",
            "hi       tiene 100 imágenes\n",
            "ho       tiene 100 imágenes\n",
            "ii       tiene 100 imágenes\n",
            "ka       tiene 100 imágenes\n",
            "ke       tiene 100 imágenes\n",
            "ki       tiene 100 imágenes\n",
            "ko       tiene 100 imágenes\n",
            "ku       tiene 100 imágenes\n",
            "ma       tiene 100 imágenes\n",
            "me       tiene 100 imágenes\n",
            "mi       tiene 100 imágenes\n",
            "mo       tiene 100 imágenes\n",
            "mu       tiene 100 imágenes\n",
            "na       tiene 100 imágenes\n",
            "ne       tiene 100 imágenes\n",
            "ni       tiene 100 imágenes\n",
            "nn       tiene 100 imágenes\n",
            "no       tiene 100 imágenes\n",
            "nu       tiene 100 imágenes\n",
            "oo       tiene 100 imágenes\n",
            "ra       tiene 100 imágenes\n",
            "re       tiene 100 imágenes\n",
            "ri       tiene 100 imágenes\n",
            "ro       tiene 100 imágenes\n",
            "ru       tiene 100 imágenes\n",
            "sa       tiene 100 imágenes\n",
            "se       tiene 100 imágenes\n",
            "shi      tiene 100 imágenes\n",
            "so       tiene 100 imágenes\n",
            "su       tiene 100 imágenes\n",
            "ta       tiene 100 imágenes\n",
            "te       tiene 100 imágenes\n",
            "to       tiene 100 imágenes\n",
            "tsu      tiene 100 imágenes\n",
            "uu       tiene 100 imágenes\n",
            "wa       tiene 100 imágenes\n",
            "wo       tiene 100 imágenes\n",
            "ya       tiene 100 imágenes\n",
            "yo       tiene 100 imágenes\n",
            "yu       tiene 100 imágenes\n",
            "\n",
            "\n",
            "RESUMEN:\n",
            "Total de caracteres: 46\n",
            "Total de imágenes: 4600\n",
            "\n",
            "Estadísticas:\n",
            "  - Mínimo: 100 imágenes\n",
            "  - Máximo: 100 imágenes\n",
            "  - Promedio: 100.00 imágenes\n",
            "  - Mediana: 100 imágenes\n",
            "\n",
            "Clases con exactamente 100 imágenes: 46/46\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# División de datos en entrenamiento y prueba"
      ],
      "metadata": {
        "id": "_OBvuZzf1MYv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import shutil\n",
        "\n",
        "# Configuración de la división\n",
        "TRAIN_RATIO = 0.70  # 70% entrenamiento\n",
        "VAL_RATIO = 0.15    # 15% validación\n",
        "TEST_RATIO = 0.15   # 15% test\n",
        "\n",
        "print(\" Configuración de división del dataset:\")\n",
        "print(\"\\n\")\n",
        "print(f\"Train: {TRAIN_RATIO*100:.0f}% ({int(100*TRAIN_RATIO)} imágenes por clase)\")\n",
        "print(f\"Validation: {VAL_RATIO*100:.0f}% ({int(100*VAL_RATIO)} imágenes por clase)\")\n",
        "print(f\"Test: {TEST_RATIO*100:.0f}% ({int(100*TEST_RATIO)} imágenes por clase)\")\n",
        "print(f\"\\nTotal por clase: 100 imágenes\")\n",
        "print(\"\\n\")\n",
        "\n",
        "# Crear estructura de directorios\n",
        "base_output_path = \"/content/hiragana_dataset\"\n",
        "splits = ['train', 'val', 'test']\n",
        "\n",
        "# Crear carpetas\n",
        "for split in splits:\n",
        "    split_path = os.path.join(base_output_path, split)\n",
        "    os.makedirs(split_path, exist_ok=True)\n",
        "    print(f\" Creado: {split_path}\")\n",
        "\n",
        "print(\"\\nProcesando división del dataset...\")\n",
        "\n",
        "# Realizar la división estratificada para cada clase\n",
        "np.random.seed(42)  # Para reproducibilidad\n",
        "\n",
        "stats = {\n",
        "    'train': 0,\n",
        "    'val': 0,\n",
        "    'test': 0\n",
        "}\n",
        "\n",
        "for character in sorted(df_hiragana['caracter']):\n",
        "    # Obtener la ruta de la carpeta del carácter\n",
        "    source_folder = os.path.join(hiragana_path, character)\n",
        "\n",
        "    # Obtener lista de imágenes\n",
        "    images = [f for f in os.listdir(source_folder)\n",
        "              if f.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif'))]\n",
        "\n",
        "    # Mezclar aleatoriamente\n",
        "    np.random.shuffle(images)\n",
        "\n",
        "    # Calcular índices de división\n",
        "    n_images = len(images)\n",
        "    train_end = int(n_images * TRAIN_RATIO)\n",
        "    val_end = train_end + int(n_images * VAL_RATIO)\n",
        "\n",
        "    # Dividir las imágenes\n",
        "    train_images = images[:train_end]\n",
        "    val_images = images[train_end:val_end]\n",
        "    test_images = images[val_end:]\n",
        "\n",
        "    # Crear carpetas para cada split\n",
        "    for split in splits:\n",
        "        split_char_path = os.path.join(base_output_path, split, character)\n",
        "        os.makedirs(split_char_path, exist_ok=True)\n",
        "\n",
        "    # Copiar imágenes a sus respectivas carpetas\n",
        "    # TRAIN\n",
        "    for img in train_images:\n",
        "        src = os.path.join(source_folder, img)\n",
        "        dst = os.path.join(base_output_path, 'train', character, img)\n",
        "        shutil.copy2(src, dst)\n",
        "        stats['train'] += 1\n",
        "\n",
        "    # VALIDATION\n",
        "    for img in val_images:\n",
        "        src = os.path.join(source_folder, img)\n",
        "        dst = os.path.join(base_output_path, 'val', character, img)\n",
        "        shutil.copy2(src, dst)\n",
        "        stats['val'] += 1\n",
        "\n",
        "    # TEST\n",
        "    for img in test_images:\n",
        "        src = os.path.join(source_folder, img)\n",
        "        dst = os.path.join(base_output_path, 'test', character, img)\n",
        "        shutil.copy2(src, dst)\n",
        "        stats['test'] += 1\n",
        "\n",
        "print(\"\\nDivisión completada!\")\n",
        "print(\"\\nResumen de la división:\")\n",
        "print(\"\\n\")\n",
        "print(f\"Train:      {stats['train']:4d} imágenes ({stats['train']/4600*100:.1f}%)\")\n",
        "print(f\"Validation: {stats['val']:4d} imágenes ({stats['val']/4600*100:.1f}%)\")\n",
        "print(f\"Test:       {stats['test']:4d} imágenes ({stats['test']/4600*100:.1f}%)\")\n",
        "print(f\"Total:      {sum(stats.values()):4d} imágenes\")\n",
        "print(\"\\n\")"
      ],
      "metadata": {
        "id": "WKcEMMdj1R94",
        "outputId": "f80fcee9-aff2-415a-c6c7-a405a2e5c5d1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Configuración de división del dataset:\n",
            "\n",
            "\n",
            "Train: 70% (70 imágenes por clase)\n",
            "Validation: 15% (15 imágenes por clase)\n",
            "Test: 15% (15 imágenes por clase)\n",
            "\n",
            "Total por clase: 100 imágenes\n",
            "\n",
            "\n",
            " Creado: /content/hiragana_dataset/train\n",
            " Creado: /content/hiragana_dataset/val\n",
            " Creado: /content/hiragana_dataset/test\n",
            "\n",
            "Procesando división del dataset...\n",
            "\n",
            "División completada!\n",
            "\n",
            "Resumen de la división:\n",
            "\n",
            "\n",
            "Train:      3220 imágenes (70.0%)\n",
            "Validation:  690 imágenes (15.0%)\n",
            "Test:        690 imágenes (15.0%)\n",
            "Total:      4600 imágenes\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(os.scandir())"
      ],
      "metadata": {
        "id": "KbfyXt841pZj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}